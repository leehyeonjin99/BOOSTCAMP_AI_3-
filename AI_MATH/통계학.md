<div align='center'>
  <h1> 통계학(Statistics) </h1>
</div>

## 모수
- 통계적 모델링 : 적절한 가저 위에서 확률분포 추정
- 유한한 데이터만으로는 정확한 모집단 분포를 알아내기는 어렵다.

|방법론|설명|
|:---:|:---:|
|모수적 방법론|모집단이 어떤 분포를 따른다는 가정하에 모수 추론|
|비모수적 방법론|특정 확률 분포 가정없이 데이터에 따라 모델의 구조 및 모수의 개수가 유연하게 변경|

- 확률 분포 가정 예시 : 보통 히스토그램 확인
   - 데이터 2개 : 베르누이분포
   - 데이터 이산적 n개 : 카테고리분포
   - 데이터 [0,1] 사이 : 베타분포
   - 데이터 0 이상의 값 : 감마분포, 로그 정규분포
   - 데이터 실수 전체 : 정규분포, 라플라스분포  
   
 - 모수를 추론한 후 각 분포마다 적절한 방법으로 검정을 실시해야한다.

### 데이터로 모수 추정하기
- 정규분포의 모수 : <img src="https://latex.codecogs.com/svg.image?\mu,{\sigma}^{2}" />
- 표본 평균 <img src="https://latex.codecogs.com/svg.image?{\over{X}}=\frac{1}{N}\sum_{i=1}^{N}X_i" />
- 표본 분산 <img src="https://latex.codecogs.com/svg.image?{S}^{2}={\frac{1}{N-1}}{\sum_{i=1}^{N}{(X_i-{\over{X}})}^{2}}" />  
  <img src="https://latex.codecogs.com/svg.image?{\rightarrow}E({\over{X}})={\mu},E({S}^{2})={\sigma}^{2}" />
- 통계량의 확률분포, 즉 표집분포는 N이 커질수록 정규분포 <img src="https://latex.codecogs.com/svg.image?N({\mu},\frac{{\sigma}^{2}}{N})" width=50/>을 따른다. : <img src="https://latex.codecogs.com/svg.image?{\over{X}}{\sim}N({\mu},\frac{{\sigma}^{2}}{N})" />
- `중심 극한 정리` : 모집단이 정규분포를 따르지 않더라도 표본의 개수가 커질수록 표집분포는 정규분포를 따른다.

## 최대 가능도 추정법(Maximum Likelihood Estimation, MSE) : 가장 가능성이 높은 모수를 측정하는 방법
가능도 함수 = <img src="https://latex.codecogs.com/svg.image?L(\theta|x)=P(x|\theta)=\Pi_{k=1}^{n}P(x_k|\theta)"/>

표본이 독립적으로 추출되면 로그가능도를 사용한다. 즉, 양변에 <img src="https://latex.codecogs.com/svg.image?log"/>를 취해준다. :  연산량이 <img src="https://latex.codecogs.com/svg.image?O({n}^{2}){\rightarrow}O(n)"/>

<img src="https://user-images.githubusercontent.com/57162812/150333791-40fdf732-0f5b-4498-85a8-a46a174b5e14.png" width=400>

<details> <summary>정규분포 MLE</summary>

![image](https://user-images.githubusercontent.com/57162812/150336509-06f72352-d0ed-4b09-984b-6c0d355120a2.png)
![image](https://user-images.githubusercontent.com/57162812/150336545-62ee59a2-8b7b-4b1a-bcf8-af17490c3d35.png)
- 두 미분이 모두 0이 되는 모수를 찾으면 가능도를 최대화하게 된다.
![image](https://user-images.githubusercontent.com/57162812/150336606-312548c2-eaea-47da-bb7a-e88f75e9ea3e.png)
- MLE는 불편 추정량을 보장하지 않는다는 사실을 알 수 있다.
  
</details>

<details> <summary>카테고리 분포 MLE</summary>
  
![image](https://user-images.githubusercontent.com/57162812/150336702-cc25421e-94af-44f8-9724-7aa05ca3aec2.png)
![image](https://user-images.githubusercontent.com/57162812/150336811-7fc70789-7650-44f4-a760-41e246056365.png)
![image](https://user-images.githubusercontent.com/57162812/150336846-dfe261cc-8f56-4d6f-9ea6-c8e19e2abf70.png)
- 카테고리 분포에는 오른쪽 식과 같은 제약식이 존재한다. : 다음과 같이 라그랑주 승수법을 통해 최적화 문제를 풀 수 있다.

![image](https://user-images.githubusercontent.com/57162812/150337077-66c85fb5-2b27-4e92-bda1-ab0d6c7f5f9e.png)
![image](https://user-images.githubusercontent.com/57162812/150337153-1127a78d-8ab5-4fad-a90c-d2ba81aa39b4.png)
- 카테고리 분포의 MLE는 경우의 수를 세어서 비율을 구하는 것이다.
  
</details>

</details>

<details> <summary>딥러닝 MLE</summary>

- 가중치를 <img src="https://latex.codecogs.com/svg.image?\theta"/>라고 표기했을 때 분류 문제에서 소프트맥스 벡터는 카테고리분포의 모수 <img src="https://latex.codecogs.com/svg.image?(p_1,p_2,...,p_k)">를 모델링한다.
  
- 정답 레이블을 원핫벡터로 표현해 관찰데이터로 활용하여 소프트맥스 벡터의 로그 가능도를 최적화
  ![image](https://user-images.githubusercontent.com/57162812/150337790-0be4c80f-9f44-4640-a9cd-3fc010a35f42.png)

  </details>
  
## 확률 분포의 거리
학습 데이터의 확률 분포와 데이터에서 관찰되는 확률 분포의 거리로 손실함수를 유도한다.
- 총 변동 거리
- 쿨백-라이블러 발산
- 바슈타인 거리

### 쿨백-라이블러 발산
![image](https://user-images.githubusercontent.com/57162812/150338057-a43df73a-ece4-4835-81a9-2ff630489587.png)
- 쿨백 라이블러는 다음과 같이 크로스 엔트로피와 엔트로피로 분해 가능하다.
![image](https://user-images.githubusercontent.com/57162812/150338163-6be2dc14-5642-48c8-b570-9448e5b9ab67.png)
- 정답레이블 P와 예측 레이블을 Q라 하면 최대가능도 추정법은 쿨백-라이블러 발산을 최소화하는 것과 같다.
