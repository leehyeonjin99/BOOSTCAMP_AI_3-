# SMP
SMPëŠ” `segmentation models pytorch`ì˜ ì•½ìë¡œ pytorchë¥¼ ê¸°ë°˜ìœ¼ë¡œ Image Segmentationì„ ìœ„í•œ Neural Networkì˜ python ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë‹¤.

## ğŸ›  Installation

```python
pip install -U segmentation_models_pytorch
```

## â³ ì‹¤í–‰ ë°©ë²•

- segmentation model : Unet
- encoder : resnet34

```python
import segmentation_models_pytorch as smp
model = smp.Unet(
    encoder_nmae = "resnet34",
    encoder_weights = "imagenet",
    in_channels = 1,
    classes = 3
)
```

## ğŸ“¦ Segmentation Models

- [ ] Unet
- [ ] Unet++
- [ ] MAnet
- [ ] Linknet
- [ ] FPN
- [ ] PSPNet
- [ ] PAN
- [ ] DeepLabV3
- [ ] DeepLabV3+

### Parameter
- `encoder_name` : encoderë¡œ ì‚¬ìš©í•  classificationì˜ ì´ë¦„
- `encoder_depth` : encoderì—ì„œ ì‚¬ìš©ë˜ëŠ” stageì˜ ìˆ˜
- `encoder_weight` : pretrained weight
- `classes` : class ìˆ˜

## ğŸ” Encoders

- [ ] ResNet
- [ ] ResNeXt
- [ ] ResNeSt
- [ ] Res2Ne(X)t
- [ ] RegNet(x/y)
- [ ] GERNet
- [ ] SE-Net
- [ ] SK-ResNe(X)t
- [ ] DenseNet
- [ ] Inception
- [ ] EfficientNet
- [ ] MobileNet
- [ ] DPN
- [ ] VGG

### swin transformer
swin transformerê°€ encoderë¡œ ë“±ë¡ë˜ì–´ ìˆì§€ ì•Šì•„ì„œ ë”°ë¡œ ë“±ë¡í•´ì£¼ì—ˆë‹¤. ê·¸ ì¤‘ swin largeë¥¼ ë“±ë¡í•´ë³´ì•˜ë‹¤.

- swin.py ìƒì„±
[Swin Transformer github](https://github.com/microsoft/Swin-Transformer/blob/main/models/swin_transformer.py)

- swin transformer large encoder ë“±ë¡

<p align="center"><img src="https://user-images.githubusercontent.com/57162812/167435667-73ded0aa-5d99-44c2-bd81-c24766b8abf6.png" width = "80%"></p>


```python
from swin import SwinTransformer
from segmentation_models_pytorch.encoders._base import EncoderMixin
from typing import List

# Custom SwinEncoder ì •ì˜
class SwinEncoder(torch.nn.Module, EncoderMixin):

    def __init__(self, **kwargs):
        super().__init__()

        # A number of channels for each encoder feature tensor, list of integers
        self._out_channels: List[int] = [192, 384, 768, 1536]

        # A number of stages in decoder (in other words number of downsampling operations), integer
        # use in in forward pass to reduce number of returning features
        self._depth: int = 3

        # Default number of input channels in first Conv2d layer for encoder (usually 3)
        self._in_channels: int = 3
        kwargs.pop('depth')

        self.model = SwinTransformer(**kwargs)

    def forward(self, x: torch.Tensor) -> List[torch.Tensor]:
        outs = self.model(x)
        return list(outs)

    def load_state_dict(self, state_dict, **kwargs):
        self.model.load_state_dict(state_dict['model'], strict=False, **kwargs)

# Swinì„ smpì˜ encoderë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë“±ë¡
def register_encoder():
    smp.encoders.encoders["swin_encoder"] = {
    "encoder": SwinEncoder, # encoder class here
    "pretrained_settings": { # pretrained ê°’ ì„¤ì •
        "imagenet": {
            "mean": [0.485, 0.456, 0.406],
            "std": [0.229, 0.224, 0.225],
            "url": "https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22kto1k.pth",
            "input_space": "RGB",
            "input_range": [0, 1],
        },
    },
    "params": { # ê¸°ë³¸ íŒŒë¼ë¯¸í„°
        "pretrain_img_size": 384,
        "embed_dim": 192,
        "depths": [2, 2, 18, 2],
        'num_heads': [6, 12, 24, 48],
        "window_size": 12,
        "drop_path_rate": 0.3,
    }
}
```


