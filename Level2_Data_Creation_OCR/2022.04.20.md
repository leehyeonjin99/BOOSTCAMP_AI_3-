# ✔️실험
### 실험 목표

- ICDAR2019 + ICDAR ArT에 대해서 더 나은 성과를 얻을 수 있다.
- optimizer, scheduler 수정

### 동기

- 대회 기간까지 얼마 남지 않은 것을 고려해 epoch를 줄이고 이에 맞는 learning rate scheduler 설정

### 과정

- Dataset : ICDAR2019 + ICDAR ArT
- max epoch : 150
  - 대회 직전 종료 시점을 고려하여 200 → 150
- optimizer : `MADGRAD` with start learning rate 0.001
  - optimizer 실험 결과에 따른 선택
- scheduler : `MultiStepLR` with milestones = [50, 100]
  - learning rate의 지속적인 유지로 인해 최적의 값으로 찾아가지 못하는 듯 하여 [max epoch//2] → [max epoch//3, max epoch//3\*2]


### 결과

|epoch|mean loss|test f1|test recall|test recall|
|:-:|:-:|:-:|:-:|:-:|
|40|0.8057|0.6160|0.5237|0.7477|
|65|0.6347|0.6897|0.6076|0.7974|
|90|0.574|0.6623|0.5823|0.7678|
|95|0.5647|0.6504|0.5646|0.7668|
|100|0.5422|0.6438|0.5597|0.7577|
# ✔️피드백
### 알게된 점

- optimizer 변경의 효과는 있었다. optimizer와 learning rate가 같은 시점에서 Adam과 MADGRAD를 비교해본 결과 0.6095와 0.6160으로 MADGRAD 사용시 조금 더 높은 것을 알 수 있었다.
- 2022.02.21 기준 제출해본 결과는 epoch가 진행될수록 f1 score가 떨어진다느 사실을 알 수 있다. 이는 과적합이 원인으로 추측될 수 있다. 만약 valid deteval을 추가해서 제출을 해보았다면 결과가 달라졌을까?

### 아쉬운 점

- 해당 실험은 150 epoch까지 측정하지 못할 것 같아 아쉽다.


### 앞으로의 방향
- polygon annotation 수정 방법 정확히 이해하기
- validation deteval 방법 정확히 이해하기
- 내일이 마지막 대회날이다. 마지막까지 최선을 다하자!!🔥🔥🔥🔥

