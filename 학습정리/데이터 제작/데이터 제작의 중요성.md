# Software 1.0 vs. Software 2.0
## Software 1.0
**개발 과정**
1. 문제 정의
2. 큰 문제를 작은 문제들의 집합으로 분해
3. 개별 문제 별로 알고리즘 설계
4. 솔루션들을 합쳐 하나의 

ex. Human Detection : 전신이 존재할 확률 + 특정 신체 일부가 존재할 확률 →Combined Score

- 2008 DPM-v1 : 21.8%
- 2014 DPM-v5 : 33.7% (**+12.7%**)
- 2020 SW2.0 : 89.3% (**55.6%**)

▶ Vision에서는 Software2.0 방식이 더 적합하다.

## Visual Recognition Task

<p align="center"><img src="https://user-images.githubusercontent.com/57162812/163218901-d440c029-5999-4322-a582-e6431a5436b0.png" width="70%"></p>

- **SW1.0**
  - 특징 추출에 필요한 연산을 `사람`이 개입했다.
- **SW2.0**
  - 사람의 개입 X
  - 특징 추출을 컴퓨터에게 맡김

## Software 2.0
**사람의 개입 없이 특정 연산들이 정의되는 방법은?**

<p align="center"><img src="https://user-images.githubusercontent.com/57162812/163221973-1f7d6b46-f086-4f23-805f-f900bc5eab84.png" width="50%"></p>

1. Nueral Net 구조에 의해서 검색 영역이 정해진다.
2. 최적화를 통해 사람이 정한 목적에 제일 부합하는 연산의 집합을 찾는다.
3. 이때, 경로와 목적지는 `데이터`와 `최적화 방법`에 의해서 정해진다.
    - 데이터와 최적화 방법의 조합에 따라서 경로와 목적지는 상이하다.

> 전체 시스템을 생각해보면 보통 레거시 시스템은 SW1.0으로 작성되어있다. 여기에서 특정 모듈, 즉 SW2.0이 더 성능이 좋다는 모듈이 SW2.0으로 개발된다.
>
> <p align="center"><img src="https://user-images.githubusercontent.com/57162812/163222885-94d88912-5e15-4f7f-afce-f8636bfab69d.png" width="50%"></p>

# Life Cycle of an AI Project
## AI Research vs. AI Production
보통 수업/학교/연구에서는 정해진 데이터셋/평가 방식에서 더 좋은 모델을 찾는 일을 한다.

<p align="center"><img src="https://user-images.githubusercontent.com/57162812/163223175-cb7fdd6c-60d9-4144-922d-3d1a1a5d134f.png" width="40%"></p>

하지만, 서비스 개발 시에는 데이터셋이 준비되어 있지 않고 요구사항만 존재한다.

<p align="center"><img src="https://user-images.githubusercontent.com/57162812/163223282-513d2dac-75bd-41f6-a464-2d4240acf894.png" width="40%"></p>

## Production Process of AI Model
**서비스향 AI 모델 개발**
1. Project Setup : 모델 요구사항 확정 (처리 시간, 목표 정확도, ⋯)
2. Data Preparation : 데이터셋 준비(종류, 수량, 정답)
3. Model Training : 모델 학습 및 디버깅(데이터 관련 피드백 / 요구사항 달성)
4. Deploying : 설치 및 유지 보수(성능 모니터링 / 이슈 해결)

**요구사항 지속적으로 충족**

<p align="center"><img src="https://user-images.githubusercontent.com/57162812/163224604-7f77be70-35c9-4f17-8a9e-7973fec2ed91.png" width="60%"></p>


1. Data-Centric : 모델 고정, 데이터 수정
    - 모델 요구사항 달성을 위해
    - 사용 중인 모델의 성능 개선을 위해
2. Model-Centric : 모델 수정, 데이터 고정

**모델 성능 달성에서의 각각의 비중은?**
[Deploy 전] Data 50% + Model 50%

[Deploy 후] Data 80% + Model 20%

**why?**

서비스 출시 후에는 정확도에 대한 성능 개선 요구가 가장 많다. 따라서, 정확도 개선을 위해 모델을 수정하게 되면 처리 비용이 커진다.

# Data
## Data-related tasks
예상보다 데이터와 관련된 업무가 많다.
1. 어떻게 하면 좋을지에 대해서 알려져 있지 않다.
    > 학계에서 데이터를 다루기 힘든 이유
    > 1. 데이터를 모으기 힘들다.
    > 2. 라벨링 비용이 크다.
    > 3. 작업 기간이 오래 걸린다.
2. 데이터 라벨링 작업은 생각보다 많이 어렵다.
    - 라벨링 결과에 대한 노이즈 → 노이즈를 무시하기 위해서는 깨끗한 데이터가 2배 이상 필요
    > 1. Small Data + Noise = 일반화 성능 하락
    > 2. Big Data + Noise = 좋은 모델 가능하지만 꺠끗한 데이터가 많아야한다.
    > 3. Small Data + Unnoise + Data Balance = 적은 데이터로 좋은 모델 확보 가능
    > 4. Small Data + Unnoise + Data Unbalance = 일반화 성능 하락

3. 데이터 불균형을 바로 잡기가 많이 어렵다.
    - 특이 경우를 발견 & 샘플을 모아야 한다. → 해당 데이터를 포함한 라벨링 가이드 필요
    - **골고루** , **일정한** 라벨링

**이 작업의 효율성을 높이기 위해서는?**

경험치가 있어야 하며, 반복적이고 자동화된 작업으로 변경해야한다.




